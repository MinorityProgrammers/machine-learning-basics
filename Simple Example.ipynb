{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDB dataset\n",
    "imdb = tf.keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "\"\"\"The argument num_words=10000 means you’ll only keep the top 10,000 most fre-\n",
    "quently occurring words in the training data. Rare words will be discarded. This allows\n",
    "you to work with vector data of manageable size.\n",
    "The variables train_data and test_data are lists of reviews; each review is a list of\n",
    "word indices (encoding a sequence of words). train_labels and test_labels are\n",
    "lists of 0s and 1s, where 0 stands for negative and 1 stands for positive:\"\"\"\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
    "num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"You can’t feed lists of integers into a neural network. You have to turn your lists into\n",
    "tensors.One-hot encode your lists to turn them into vectors of 0s and 1s. This would\n",
    "mean, for instance, turning the sequence [3, 5] into a 10,000-dimensional vec-\n",
    "tor that would be all 0s except for indices 3 and 5, which would be 1s. Then you\n",
    "could use as the first layer in your network a Dense layer, capable of handling\n",
    "floating-point vector data.\"\"\"\n",
    "\n",
    "# Encoding the integer sequences into a binary matrix\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here’s what the samples look like now:\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The intermediate layers will use relu as their activation function, and the final layer\\nwill use a sigmoid activation so as to output a probability (a score between 0 and 1,\\nindicating how likely the sample is to have the target “1”: how likely the review is to be\\npositive). A relu (rectified linear unit) is a function meant to zero out negative values.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"There is more to this but for the time being, you’ll have to trust me with the following architecture choice:\"\"\"\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(16, activation='relu', input_shape=(10000,)),\n",
    "  tf.keras.layers.Dense(16, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "\"\"\"Two intermediate layers with 16 hidden units each. And a third layer that will output the scalar prediction \n",
    "regarding the sentiment of the current review\"\"\"\n",
    "\n",
    "\"\"\"The intermediate layers will use relu as their activation function, and the final layer\n",
    "will use a sigmoid activation so as to output a probability (a score between 0 and 1,\n",
    "indicating how likely the sample is to have the target “1”: how likely the review is to be\n",
    "positive). A relu (rectified linear unit) is a function meant to zero out negative values.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f1ffb8feb90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f1ffb8feb90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "15000/15000 [==============================] - 2s 164us/sample - loss: 0.4966 - accuracy: 0.7892 - val_loss: 0.3636 - val_accuracy: 0.8754\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 2s 103us/sample - loss: 0.2850 - accuracy: 0.9109 - val_loss: 0.2945 - val_accuracy: 0.8895\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 1s 97us/sample - loss: 0.2125 - accuracy: 0.9287 - val_loss: 0.2793 - val_accuracy: 0.8889\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 1s 95us/sample - loss: 0.1682 - accuracy: 0.9461 - val_loss: 0.2959 - val_accuracy: 0.8793\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 1s 97us/sample - loss: 0.1348 - accuracy: 0.9585 - val_loss: 0.3318 - val_accuracy: 0.8685\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 2s 115us/sample - loss: 0.1148 - accuracy: 0.9637 - val_loss: 0.3523 - val_accuracy: 0.8713\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 1s 97us/sample - loss: 0.0932 - accuracy: 0.9731 - val_loss: 0.3424 - val_accuracy: 0.8773\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 1s 98us/sample - loss: 0.0795 - accuracy: 0.9774 - val_loss: 0.3738 - val_accuracy: 0.8693\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 2s 103us/sample - loss: 0.0671 - accuracy: 0.9820 - val_loss: 0.3581 - val_accuracy: 0.8801\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 1s 99us/sample - loss: 0.0527 - accuracy: 0.9879 - val_loss: 0.3874 - val_accuracy: 0.8770\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 1s 98us/sample - loss: 0.0458 - accuracy: 0.9887 - val_loss: 0.4321 - val_accuracy: 0.8740\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 1s 97us/sample - loss: 0.0352 - accuracy: 0.9928 - val_loss: 0.4427 - val_accuracy: 0.8710\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 2s 102us/sample - loss: 0.0300 - accuracy: 0.9933 - val_loss: 0.4888 - val_accuracy: 0.8643\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 2s 101us/sample - loss: 0.0241 - accuracy: 0.9957 - val_loss: 0.5142 - val_accuracy: 0.8703\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 1s 99us/sample - loss: 0.0223 - accuracy: 0.9951 - val_loss: 0.5390 - val_accuracy: 0.8705\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 1s 100us/sample - loss: 0.0122 - accuracy: 0.9991 - val_loss: 0.5800 - val_accuracy: 0.8633\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 2s 108us/sample - loss: 0.0137 - accuracy: 0.9978 - val_loss: 0.6020 - val_accuracy: 0.8657\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 1s 98us/sample - loss: 0.0115 - accuracy: 0.9981 - val_loss: 0.6386 - val_accuracy: 0.8652\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 1s 98us/sample - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.6718 - val_accuracy: 0.8632\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 2s 102us/sample - loss: 0.0081 - accuracy: 0.9987 - val_loss: 0.7056 - val_accuracy: 0.8630\n"
     ]
    }
   ],
   "source": [
    "# Setting aside a validation set\n",
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "history = model.fit(partial_x_train, partial_y_train, epochs=20,batch_size=512,validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the training and validation loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc1200451d0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the training and validation accuracy\n",
    "plt.clf()\n",
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "15000/15000 [==============================] - 1s 84us/sample - loss: 0.5569 - accuracy: 0.7584 - val_loss: 0.4584 - val_accuracy: 0.8571\n",
      "Epoch 2/4\n",
      "15000/15000 [==============================] - 1s 46us/sample - loss: 0.3633 - accuracy: 0.8943 - val_loss: 0.3461 - val_accuracy: 0.8806\n",
      "Epoch 3/4\n",
      "15000/15000 [==============================] - 1s 46us/sample - loss: 0.2634 - accuracy: 0.9231 - val_loss: 0.3016 - val_accuracy: 0.8883\n",
      "Epoch 4/4\n",
      "15000/15000 [==============================] - 1s 44us/sample - loss: 0.2076 - accuracy: 0.9382 - val_loss: 0.2808 - val_accuracy: 0.8900\n",
      "25000/25000 [==============================] - 2s 64us/sample - loss: 0.2976 - accuracy: 0.8832\n"
     ]
    }
   ],
   "source": [
    "# Retraining a model from scratch\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(16, activation='relu', input_shape=(10000,)),\n",
    "  tf.keras.layers.Dense(16, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train, partial_y_train, epochs=4,batch_size=512,validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27379423],\n",
       "       [0.9793424 ],\n",
       "       [0.93266404],\n",
       "       ...,\n",
       "       [0.13444236],\n",
       "       [0.17874026],\n",
       "       [0.4376474 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using a trained network to generate predictions on new data\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
